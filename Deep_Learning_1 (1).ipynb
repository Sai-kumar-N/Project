{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wY2-NcZaECPV"
   },
   "source": [
    "# Model -  Sequential & Functional\n",
    "\n",
    "**Sequential is the easiest way to build a model in Keras. It allows you to build a model layer by layer. Each layer has weights that correspond to the layer the follows it.**\n",
    "\n",
    "\n",
    "* We use the **‘add()’**  function to add layers to our model.\n",
    "\n",
    "\n",
    "* **‘Dense’** is the layer type. Dense is a standard layer type that works for most cases. In a dense layer, all nodes in the previous layer connect to the nodes in the current layer.\n",
    "\n",
    "\n",
    "**We define nodes in each of our input layers. This number can also be in the hundreds or thousands. Increasing the number of nodes in each layer increases model capacity. I will go into further detail about the effects of increasing model capacity shortly.**\n",
    "\n",
    "\n",
    "* **‘Activation’** is the activation function for the layer. An activation function allows models to take into account nonlinear relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRevaPp6ECPX"
   },
   "source": [
    "**The first layer needs an input shape. The input shape specifies the number of rows and columns in the input.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pTQbiteOECPY"
   },
   "source": [
    "**The last layer is the output layer. It only has one node, two nodes as per requirment. which is for our prediction.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83ZTm03EECPZ"
   },
   "source": [
    "# Compiling Model. \n",
    "\n",
    "**Compiling the model takes two parameters: optimizer and loss.**\n",
    "\n",
    "* The **optimizer** controls the learning rate. We will be using **‘adam’** as our optmizer. \n",
    "\n",
    "* Adam is generally a good optimizer to use for many cases. The adam optimizer adjusts the learning rate throughout training.\n",
    "\n",
    "* The learning rate determines how fast the optimal weights for the model are calculated. A smaller learning rate may lead to more accurate weights (up to a certain point), but the time it takes to compute the weights will be longer.\n",
    "\n",
    "* For our loss function, we will use ‘as per requirment ( regression or Classification’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAOm-0lsECPa"
   },
   "source": [
    "# Train\n",
    "\n",
    "* we will use the ‘fit()’ function on our model with the following five parameters: \n",
    "* training data (train_X), \n",
    "* target data (train_y), \n",
    "* validation split, \n",
    "* number of epochs \n",
    "* callbacks.\n",
    "\n",
    "* The validation split will randomly split the data into use for training and testing. \n",
    "\n",
    "* During training, we will be able to see the validation loss, If we will set the validation split at 0.2, which means that 20% of the training data we provide in the model will be set aside for testing model performance.\n",
    "\n",
    "* The number of epochs is the number of times the model will cycle through the data. The more epochs we run, the more the model will improve, up to a certain point. After that point, the model will stop improving during each epoch. In addition, the more epochs, the longer the model will take to run. To monitor this, we will use ‘early stopping’.\n",
    "\n",
    "* Early stopping will stop the model from training before the number of epochs is reached if the model stops improving. We will set our early stopping monitor to 3. This means that after 3 epochs in a row in which the model doesn’t improve, training will stop. Sometimes, the validation loss can stop improving then improve in the next epoch, but after 3 epochs in which the validation loss doesn’t improve, it usually won’t improve again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkTXN3SkECPb"
   },
   "source": [
    "* to make predictions on new data, we would use the *‘predict()’* function, passing in our new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e9M2hRzxECPc"
   },
   "source": [
    "**As you increase the number of nodes and layers in a model, the model capacity increases. Increasing model capacity can lead to a more accurate model, up to a certain point, at which the model will stop improving. Generally, the more training data you provide, the larger the model should be.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9pgXM8wECPc"
   },
   "source": [
    "#  Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install tensorflow --- in anaconda prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99293I--mwjt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2537BMEcnAHU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential    #  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTeJJ5TpnAWJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "speqEhqPn5Vb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oRtmuChnAm-"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/shyam/Documents/datasets/IRIS.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "Y6_rZHcYotks",
    "outputId": "4c2400dd-aee2-41ce-f689-78ab5879f238"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "X_Z6bn2lpXsR",
    "outputId": "82c558c2-9201-4eb7-c86e-920542489126"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    float64\n",
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "species          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xxi3wIcqpXvV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOfP7EX2tCcY"
   },
   "outputs": [],
   "source": [
    "data['species'] = lc.fit_transform(data['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "HhFh4-wIpXwv",
    "outputId": "6e287b19-4677-4f3e-c8a0-73057f706479"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "jx6WhAMkpXzf",
    "outputId": "28c94661-1477-4fc5-b929-43027e0ccbd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eNAPEH1pX0x"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "RnrNWRpTpX4v",
    "outputId": "e22ce3f2-a72d-4526-83a0-c32dd214ea5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "0           5.1          3.5           1.4          0.2\n",
       "1           4.9          3.0           1.4          0.2\n",
       "2           4.7          3.2           1.3          0.2\n",
       "3           4.6          3.1           1.5          0.2\n",
       "4           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9lWotpXpYEi"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6VM4X5LBpX_P",
    "outputId": "6daaa873-1280-47e1-bd9b-de23b8540512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.1728 - accuracy: 0.6261 - val_loss: 1.1915 - val_accuracy: 0.5833\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1849 - accuracy: 0.5932 - val_loss: 1.1676 - val_accuracy: 0.5833\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1459 - accuracy: 0.6041 - val_loss: 1.1544 - val_accuracy: 0.5833\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0979 - accuracy: 0.6599 - val_loss: 1.1442 - val_accuracy: 0.5417\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1158 - accuracy: 0.5929 - val_loss: 1.1309 - val_accuracy: 0.5417\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1105 - accuracy: 0.5833 - val_loss: 1.1212 - val_accuracy: 0.5417\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0738 - accuracy: 0.6740 - val_loss: 1.1190 - val_accuracy: 0.5000\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0944 - accuracy: 0.5496 - val_loss: 1.1122 - val_accuracy: 0.5000\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0759 - accuracy: 0.5990 - val_loss: 1.1107 - val_accuracy: 0.5000\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0621 - accuracy: 0.6113 - val_loss: 1.1072 - val_accuracy: 0.5000\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.4516 - val_loss: 1.1014 - val_accuracy: 0.2917\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0646 - accuracy: 0.3852 - val_loss: 1.0975 - val_accuracy: 0.2917\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0648 - accuracy: 0.3656 - val_loss: 1.0972 - val_accuracy: 0.2500\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0693 - accuracy: 0.3075 - val_loss: 1.0906 - val_accuracy: 0.2083\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0591 - accuracy: 0.3293 - val_loss: 1.0888 - val_accuracy: 0.2083\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0499 - accuracy: 0.3675 - val_loss: 1.0850 - val_accuracy: 0.2083\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0413 - accuracy: 0.3799 - val_loss: 1.0840 - val_accuracy: 0.2083\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.3652 - val_loss: 1.0774 - val_accuracy: 0.1667\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0482 - accuracy: 0.3148 - val_loss: 1.0721 - val_accuracy: 0.1667\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0323 - accuracy: 0.3572 - val_loss: 1.0680 - val_accuracy: 0.1667\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0301 - accuracy: 0.3597 - val_loss: 1.0647 - val_accuracy: 0.1667\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0361 - accuracy: 0.3261 - val_loss: 1.0578 - val_accuracy: 0.1667\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0281 - accuracy: 0.3180 - val_loss: 1.0517 - val_accuracy: 0.1667\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0240 - accuracy: 0.3255 - val_loss: 1.0452 - val_accuracy: 0.1667\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9956 - accuracy: 0.3993 - val_loss: 1.0403 - val_accuracy: 0.1667\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0012 - accuracy: 0.3412 - val_loss: 1.0352 - val_accuracy: 0.1667\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9823 - accuracy: 0.3712 - val_loss: 1.0281 - val_accuracy: 0.1250\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9933 - accuracy: 0.3285 - val_loss: 1.0184 - val_accuracy: 0.1250\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9877 - accuracy: 0.2700 - val_loss: 1.0068 - val_accuracy: 0.1250\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9721 - accuracy: 0.3616 - val_loss: 0.9994 - val_accuracy: 0.1667\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9531 - accuracy: 0.4680 - val_loss: 0.9874 - val_accuracy: 0.2083\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9528 - accuracy: 0.5534 - val_loss: 0.9703 - val_accuracy: 0.2917\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9352 - accuracy: 0.5927 - val_loss: 0.9492 - val_accuracy: 0.6250\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9145 - accuracy: 0.6465 - val_loss: 0.9290 - val_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9039 - accuracy: 0.5991 - val_loss: 0.9150 - val_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8991 - accuracy: 0.7175 - val_loss: 0.8904 - val_accuracy: 0.7917\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8766 - accuracy: 0.7723 - val_loss: 0.8774 - val_accuracy: 0.8750\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8560 - accuracy: 0.8103 - val_loss: 0.8514 - val_accuracy: 0.8750\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8308 - accuracy: 0.7566 - val_loss: 0.8338 - val_accuracy: 0.9167\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8273 - accuracy: 0.7805 - val_loss: 0.8161 - val_accuracy: 0.9167\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8171 - accuracy: 0.8506 - val_loss: 0.7904 - val_accuracy: 0.9167\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8129 - accuracy: 0.7594 - val_loss: 0.7772 - val_accuracy: 0.9167\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7902 - accuracy: 0.7817 - val_loss: 0.7542 - val_accuracy: 0.9167\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7361 - accuracy: 0.8210 - val_loss: 0.7274 - val_accuracy: 0.9167\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7557 - accuracy: 0.8036 - val_loss: 0.7241 - val_accuracy: 0.9167\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7164 - accuracy: 0.9206 - val_loss: 0.6946 - val_accuracy: 0.9167\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.8536 - val_loss: 0.6549 - val_accuracy: 0.9583\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.8666 - val_loss: 0.6304 - val_accuracy: 0.9583\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.8538 - val_loss: 0.6322 - val_accuracy: 0.8750\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.9130 - val_loss: 0.5904 - val_accuracy: 0.9167\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.9172 - val_loss: 0.5626 - val_accuracy: 0.9167\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.9325 - val_loss: 0.5418 - val_accuracy: 0.9167\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5540 - accuracy: 0.9593 - val_loss: 0.5278 - val_accuracy: 0.9167\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.8777 - val_loss: 0.4942 - val_accuracy: 0.9167\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.9446 - val_loss: 0.4713 - val_accuracy: 0.9167\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.9253 - val_loss: 0.4606 - val_accuracy: 0.9167\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.8920 - val_loss: 0.4377 - val_accuracy: 0.9167\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.9494 - val_loss: 0.4079 - val_accuracy: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.9551 - val_loss: 0.4028 - val_accuracy: 0.9167\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.9646 - val_loss: 0.3786 - val_accuracy: 0.9583\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.9169 - val_loss: 0.3641 - val_accuracy: 0.9583\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.8914 - val_loss: 0.3529 - val_accuracy: 0.9167\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.9185 - val_loss: 0.3355 - val_accuracy: 0.9583\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3679 - accuracy: 0.9496 - val_loss: 0.3267 - val_accuracy: 0.9583\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.9308 - val_loss: 0.3205 - val_accuracy: 0.9167\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.9259 - val_loss: 0.3115 - val_accuracy: 0.9167\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.9427 - val_loss: 0.3013 - val_accuracy: 0.9167\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3668 - accuracy: 0.9281 - val_loss: 0.2779 - val_accuracy: 0.9583\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.9342 - val_loss: 0.2717 - val_accuracy: 0.9583\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.9569 - val_loss: 0.2804 - val_accuracy: 0.9167\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.9152 - val_loss: 0.2690 - val_accuracy: 0.9167\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.9344 - val_loss: 0.2504 - val_accuracy: 0.9583\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2807 - accuracy: 0.9574 - val_loss: 0.2372 - val_accuracy: 0.9583\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3052 - accuracy: 0.9549 - val_loss: 0.2378 - val_accuracy: 0.9583\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.9651 - val_loss: 0.2328 - val_accuracy: 0.9583\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.9636 - val_loss: 0.2253 - val_accuracy: 0.9583\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9685 - val_loss: 0.2194 - val_accuracy: 0.9583\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.9303 - val_loss: 0.2169 - val_accuracy: 0.9583\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9633 - val_loss: 0.2048 - val_accuracy: 0.9583\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9325 - val_loss: 0.2062 - val_accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.9502 - val_loss: 0.1989 - val_accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9301 - val_loss: 0.1862 - val_accuracy: 0.9583\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.9515 - val_loss: 0.1950 - val_accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9649 - val_loss: 0.1878 - val_accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9742 - val_loss: 0.1812 - val_accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.9289 - val_loss: 0.1683 - val_accuracy: 0.9583\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.9048 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1819 - accuracy: 0.9872 - val_loss: 0.1630 - val_accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9673 - val_loss: 0.1595 - val_accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9404 - val_loss: 0.1646 - val_accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.9452 - val_loss: 0.1600 - val_accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2213 - accuracy: 0.9744 - val_loss: 0.1498 - val_accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2098 - accuracy: 0.9838 - val_loss: 0.1547 - val_accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2206 - accuracy: 0.9720 - val_loss: 0.1489 - val_accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.9762 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9738 - val_loss: 0.1370 - val_accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9532 - val_loss: 0.1359 - val_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9793 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.9521 - val_loss: 0.1382 - val_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2047 - accuracy: 0.9728 - val_loss: 0.1256 - val_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9498 - val_loss: 0.1278 - val_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9923 - val_loss: 0.1215 - val_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9700 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1876 - accuracy: 0.9732 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1677 - accuracy: 0.9503 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9611 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9651 - val_loss: 0.1049 - val_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9687 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9757 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1556 - accuracy: 0.9752 - val_loss: 0.1052 - val_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1847 - accuracy: 0.9528 - val_loss: 0.1008 - val_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1754 - accuracy: 0.9585 - val_loss: 0.1031 - val_accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9497 - val_loss: 0.1017 - val_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9818 - val_loss: 0.0937 - val_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9720 - val_loss: 0.1054 - val_accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1299 - accuracy: 0.9762 - val_loss: 0.0978 - val_accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9652 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1575 - accuracy: 0.9717 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9762 - val_loss: 0.0976 - val_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.9902 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9872 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9703 - val_loss: 0.1044 - val_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.9647 - val_loss: 0.0809 - val_accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9887 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9818 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.9705 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1503 - accuracy: 0.9619 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9883 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9791 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9912 - val_loss: 0.0725 - val_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9263 - val_loss: 0.0740 - val_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9889 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.9497 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1181 - accuracy: 0.9722 - val_loss: 0.0722 - val_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1211 - accuracy: 0.9791 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.9791 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1169 - accuracy: 0.9841 - val_loss: 0.0675 - val_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1359 - accuracy: 0.9561 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9652 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1544 - accuracy: 0.9510 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9566 - val_loss: 0.0649 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1276 - accuracy: 0.9676 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9717 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.9676 - val_loss: 0.0592 - val_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0971 - accuracy: 0.9913 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9665 - val_loss: 0.0641 - val_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9875 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9906 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9808 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9851 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9902 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9753 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9597 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9918 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1081 - accuracy: 0.9793 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1269 - accuracy: 0.9510 - val_loss: 0.0541 - val_accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9826 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.9860 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9873 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9664 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9652 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9744 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1229 - accuracy: 0.9641 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9528 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9705 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9831 - val_loss: 0.0427 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9688 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1205 - accuracy: 0.9763 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9928 - val_loss: 0.0419 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9744 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9646 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9791 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0767 - accuracy: 0.9952 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9682 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9862 - val_loss: 0.0393 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9884 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9784 - val_loss: 0.0406 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0801 - accuracy: 0.9831 - val_loss: 0.0401 - val_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0974 - accuracy: 0.9738 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9738 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.9470 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9887 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.9735 - val_loss: 0.0380 - val_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9864 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9773 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.9682 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9429 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9636 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9733 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0967 - accuracy: 0.9766 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0929 - accuracy: 0.9622 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9728 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1392 - accuracy: 0.9470 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9429 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9475 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9637 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9822 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0807 - accuracy: 0.9775 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9758 - val_loss: 0.0326 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 0.9353 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9893 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9902 - val_loss: 0.0290 - val_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9611 - val_loss: 0.0340 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9744 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9655 - val_loss: 0.0273 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9796 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1531 - accuracy: 0.9338 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9485 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0806 - accuracy: 0.9918 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0705 - accuracy: 0.9838 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9694 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1255 - accuracy: 0.9516 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1146 - accuracy: 0.9561 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0566 - accuracy: 0.9931 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9941 - val_loss: 0.0261 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9750 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.9561 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.9761 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9878 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9745 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9733 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9576 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9676 - val_loss: 0.0236 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9732 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9755 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9637 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9941 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9744 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9834 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9816 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9804 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9788 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9636 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9874 - val_loss: 0.0230 - val_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 0.9744 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9778 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9841 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0990 - accuracy: 0.9709 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9693 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9555 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1400 - accuracy: 0.9338 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9837 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9728 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9893 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9804 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0911 - accuracy: 0.9773 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9394 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9614 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9884 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9781 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9561 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1018 - accuracy: 0.9520 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9727 - val_loss: 0.0191 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9913 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9520 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9606 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9763 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9878 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9574 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9919 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9913 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9751 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1124 - accuracy: 0.9574 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0719 - accuracy: 0.9778 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9778 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9850 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9587 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9722 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9717 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0692 - accuracy: 0.9878 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9746 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9611 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9641 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 0.9862 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9913 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9652 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9544 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1116 - accuracy: 0.9637 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9751 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9587 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9733 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9919 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9705 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9687 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9845 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9565 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9792 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0979 - accuracy: 0.9655 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9746 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9791 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0822 - accuracy: 0.9822 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9705 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9913 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9863 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0824 - accuracy: 0.9721 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9444 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9918 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9670 - val_loss: 0.0141 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "m=model.fit(X_train,y_train, epochs=300, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RpFWHtSnAqi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97f0911ba8>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(m.history['loss'])\n",
    "plt.plot(m.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97f06af9e8>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m.history['accuracy'])\n",
    "plt.plot(m.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1796 - accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9-Qryk9nAsI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17958137392997742, 0.9666666388511658]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 2, 2, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 1, 2, 2, 0, 1,\n",
       "       2, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 0, 1, 2, 2, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 1, 2, 2, 0, 1,\n",
       "       2, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(X_test), axis=-1)  # predict classes update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yP5d3Y9nAvU"
   },
   "outputs": [],
   "source": [
    "data1=data.iloc[149:150,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cA2hbzH0nAwq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "149           5.9          3.0           5.1          1.8"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "149           5.9          3.0           5.1          1.8        2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[149:150,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test1=data.iloc[149:150,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.evaluate(data1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.6507931e-05, 2.4465264e-01, 7.5527084e-01]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data1)     #  probabilty output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bnuR0FBnA27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "a=model.predict_classes(data1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc.inverse_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_file=\"clf.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model,keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4l7zwPAtnA51"
   },
   "outputs": [],
   "source": [
    "from tensorflow import lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter= lite.TFLiteConverter.from_keras_model(keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model=converter.convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbvxeel5r/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbvxeel5r/assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asXk0WoCnAzU"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'export'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-a7d9d3c26392>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwith_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'export'"
     ]
    }
   ],
   "source": [
    "model.export(export_dir=\".\",with_metadata=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep_Learning_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
